{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5defb694",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-01-05T15:10:45.290179Z",
          "iopub.status.busy": "2025-01-05T15:10:45.289841Z",
          "iopub.status.idle": "2025-01-05T15:10:50.400968Z",
          "shell.execute_reply": "2025-01-05T15:10:50.399862Z"
        },
        "papermill": {
          "duration": 5.146256,
          "end_time": "2025-01-05T15:10:50.402957",
          "exception": false,
          "start_time": "2025-01-05T15:10:45.256701",
          "status": "completed"
        },
        "tags": [],
        "id": "5defb694",
        "outputId": "a48ed353-11f2-455d-9ead-2221fa94a35c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\r\n",
            "Collecting huggingface_hub\r\n",
            "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\r\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\r\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\r\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\r\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\r\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\r\n",
            "Downloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hInstalling collected packages: huggingface_hub\r\n",
            "  Attempting uninstall: huggingface_hub\r\n",
            "    Found existing installation: huggingface-hub 0.24.7\r\n",
            "    Uninstalling huggingface-hub-0.24.7:\r\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\r\n",
            "Successfully installed huggingface_hub-0.27.0\r\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6795619d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-05T15:10:50.466681Z",
          "iopub.status.busy": "2025-01-05T15:10:50.466428Z",
          "iopub.status.idle": "2025-01-05T15:10:51.038775Z",
          "shell.execute_reply": "2025-01-05T15:10:51.037884Z"
        },
        "papermill": {
          "duration": 0.603687,
          "end_time": "2025-01-05T15:10:51.040382",
          "exception": false,
          "start_time": "2025-01-05T15:10:50.436695",
          "status": "completed"
        },
        "tags": [],
        "id": "6795619d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "\n",
        "# login(token=\"\") #read_token\n",
        "login(token=\"\") #write_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0538ce37",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-05T15:10:51.098445Z",
          "iopub.status.busy": "2025-01-05T15:10:51.098202Z",
          "iopub.status.idle": "2025-01-05T15:11:05.566568Z",
          "shell.execute_reply": "2025-01-05T15:11:05.565623Z"
        },
        "papermill": {
          "duration": 14.498709,
          "end_time": "2025-01-05T15:11:05.568165",
          "exception": false,
          "start_time": "2025-01-05T15:10:51.069456",
          "status": "completed"
        },
        "tags": [],
        "id": "0538ce37",
        "outputId": "939097e0-aff2-47ee-8ba7-f8aac7df857c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\r\n",
            "Collecting transformers\r\n",
            "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hCollecting peft\r\n",
            "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\r\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\r\n",
            "Collecting accelerate\r\n",
            "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\r\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\r\n",
            "Collecting evaluate\r\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\r\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\r\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\r\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\r\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\r\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\r\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\r\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\r\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\r\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\r\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\r\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\r\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\r\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\r\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\r\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\r\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\r\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\r\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\r\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\r\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\r\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\r\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\r\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\r\n",
            "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading accelerate-1.2.1-py3-none-any.whl (336 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hInstalling collected packages: tokenizers, accelerate, transformers, peft, evaluate\r\n",
            "  Attempting uninstall: tokenizers\r\n",
            "    Found existing installation: tokenizers 0.19.1\r\n",
            "    Uninstalling tokenizers-0.19.1:\r\n",
            "      Successfully uninstalled tokenizers-0.19.1\r\n",
            "  Attempting uninstall: accelerate\r\n",
            "    Found existing installation: accelerate 0.34.2\r\n",
            "    Uninstalling accelerate-0.34.2:\r\n",
            "      Successfully uninstalled accelerate-0.34.2\r\n",
            "  Attempting uninstall: transformers\r\n",
            "    Found existing installation: transformers 4.44.2\r\n",
            "    Uninstalling transformers-4.44.2:\r\n",
            "      Successfully uninstalled transformers-4.44.2\r\n",
            "Successfully installed accelerate-1.2.1 evaluate-0.4.3 peft-0.14.0 tokenizers-0.21.0 transformers-4.47.1\r\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers peft accelerate datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a636fde",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-05T15:11:05.630396Z",
          "iopub.status.busy": "2025-01-05T15:11:05.630128Z",
          "iopub.status.idle": "2025-01-05T15:11:11.325750Z",
          "shell.execute_reply": "2025-01-05T15:11:11.324576Z"
        },
        "papermill": {
          "duration": 5.728309,
          "end_time": "2025-01-05T15:11:11.327522",
          "exception": false,
          "start_time": "2025-01-05T15:11:05.599213",
          "status": "completed"
        },
        "tags": [],
        "id": "6a636fde",
        "outputId": "820d86d7-acec-4a43-a447-0ea08e2b4719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bitsandbytes\r\n",
            "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\r\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.1+cu121)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\r\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\r\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\r\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\r\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\r\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\r\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\r\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\r\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\r\n",
            "Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\r\n",
            "Successfully installed bitsandbytes-0.45.0\r\n"
          ]
        }
      ],
      "source": [
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2031aba5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-05T15:11:11.390421Z",
          "iopub.status.busy": "2025-01-05T15:11:11.390155Z",
          "iopub.status.idle": "2025-01-05T15:11:27.550526Z",
          "shell.execute_reply": "2025-01-05T15:11:27.549815Z"
        },
        "papermill": {
          "duration": 16.192859,
          "end_time": "2025-01-05T15:11:27.551700",
          "exception": false,
          "start_time": "2025-01-05T15:11:11.358841",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "1e1e861935ab44c5b22526a48e8ab43b",
            "bdb4a92003144b8c85f78d6b1106da39",
            "7acb7c41247b46fbaedde9c7ef4a3e71"
          ]
        },
        "id": "2031aba5",
        "outputId": "a3e67e85-fd46-4121-e9f9-fe828eafb673"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e1e861935ab44c5b22526a48e8ab43b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "hum_ai_mala_train.csv:   0%|          | 0.00/247k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdb4a92003144b8c85f78d6b1106da39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7acb7c41247b46fbaedde9c7ef4a3e71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First example in train dataset: {'ID': 'MAL_HUAI_TR_186', 'DATA': '8 ലക്ഷതിന് ഈ വാഹനം കിട്ടൂല റോഡിൽ ഇറക്കാൻ 10 ലക്ഷം ആവും ഈ വിലയിൽ വങ്ങാൻ കിട്ടുന്ന അടിപൊളി വാഹനം', 'LABEL': 'HUMAN', 'labels': 0}\n",
            "First example in test dataset: {'ID': 'MAL_HUAI_TR_097', 'DATA': 'ഇന്റീരിയർ കൂടി ചേഞ്ച്\\u200c ആകാമായിരുന്നു കണ്ട് മടുത്ത ഡിസൈൻ', 'LABEL': 'HUMAN', 'labels': 0}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"ka05ar/Det_ai_mala_text\")\n",
        "\n",
        "\n",
        "# Preprocess labels\n",
        "\n",
        "\n",
        "from datasets import DatasetDict\n",
        "\n",
        "# Define the label mapping function\n",
        "def preprocess_labels(example):\n",
        "    label_mapping = {\"HUMAN\": 0, \"AI\": 1}\n",
        "    if \"LABEL\" in example:\n",
        "        if example[\"LABEL\"] in label_mapping:\n",
        "            example[\"labels\"] = label_mapping[example[\"LABEL\"]]\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected label: {example['LABEL']}\")\n",
        "    else:\n",
        "        raise KeyError(\"'LABEL' key not found in the dataset example.\")\n",
        "    return example\n",
        "\n",
        "# Apply preprocessing to the dataset\n",
        "processed_dataset = dataset.map(preprocess_labels)\n",
        "\n",
        "# Split the train and test sets from the processed dataset\n",
        "split_dataset = DatasetDict({\n",
        "    \"train\": processed_dataset[\"train\"].train_test_split(test_size=0.2, seed=42)[\"train\"],\n",
        "    \"test\": processed_dataset[\"train\"].train_test_split(test_size=0.2, seed=42)[\"test\"]\n",
        "})\n",
        "\n",
        "# Access the train and test datasets\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]\n",
        "\n",
        "# Verify the processed dataset\n",
        "print(f\"First example in train dataset: {train_dataset[0]}\")\n",
        "print(f\"First example in test dataset: {test_dataset[0]}\")\n",
        "\n",
        "\n",
        "\n",
        "# def preprocess_labels(example):\n",
        "#     label_mapping = {\"HUMAN\": 0, \"AI\": 1}\n",
        "#     example[\"labels\"] = label_mapping[example[\"LABEL\"]]\n",
        "#     return example\n",
        "\n",
        "\n",
        "# processed_dataset = dataset.map(preprocess_labels)\n",
        "# split_dataset = processed_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "# train_dataset = processed_dataset[\"train\"]\n",
        "# test_dataset = processed_dataset[\"validation\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68ed89b1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-05T15:11:27.614900Z",
          "iopub.status.busy": "2025-01-05T15:11:27.614668Z",
          "iopub.status.idle": "2025-01-05T15:11:31.427141Z",
          "shell.execute_reply": "2025-01-05T15:11:31.426417Z"
        },
        "papermill": {
          "duration": 3.844941,
          "end_time": "2025-01-05T15:11:31.428430",
          "exception": false,
          "start_time": "2025-01-05T15:11:27.583489",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "dce94a1c9c264177874139155bbce7c1",
            "238e6a569a0f4f83a76ddd1db4b3507d",
            "d69c12103b1c4e3b8cbe5da77f785ca5",
            "39666145c9bd47528791564ff71cc1ad",
            "6b0db1228b264018acddf4df117948d1",
            "18be63174f754256844f0f344d265273"
          ]
        },
        "id": "68ed89b1",
        "outputId": "fec77fc7-599a-44e6-8096-a4bc40cd9d83"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dce94a1c9c264177874139155bbce7c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "238e6a569a0f4f83a76ddd1db4b3507d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d69c12103b1c4e3b8cbe5da77f785ca5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39666145c9bd47528791564ff71cc1ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b0db1228b264018acddf4df117948d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/640 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18be63174f754256844f0f344d265273",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize tokenizer with proper padding setup\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as PAD token\n",
        "tokenizer.padding_side = 'right'\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"DATA\"],\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128,\n",
        "        return_tensors=None\n",
        "    )\n",
        "    tokenized['labels'] = examples['labels']\n",
        "    return tokenized\n",
        "\n",
        "# Encode datasets\n",
        "encoded_train = train_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=train_dataset.column_names\n",
        ")\n",
        "encoded_test = test_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=test_dataset.column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f93b8354",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-05T15:11:31.495366Z",
          "iopub.status.busy": "2025-01-05T15:11:31.495065Z",
          "iopub.status.idle": "2025-01-05T15:15:46.476918Z",
          "shell.execute_reply": "2025-01-05T15:15:46.475998Z"
        },
        "papermill": {
          "duration": 255.017432,
          "end_time": "2025-01-05T15:15:46.478503",
          "exception": false,
          "start_time": "2025-01-05T15:11:31.461071",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "350837d567f14ea49fdb1e11d0af5941",
            "209dd26a8d5d41dba15d8b4dc3174ea3",
            "6543dd5689e44cc1ac46f504d9e3e570",
            "d8b435189acc46b59d3f5450e7f17c7b",
            "203f488bee0b4fc2902a6e7feb29616f",
            "8423bc9208da4f3b8edbac1755cba07a",
            "5b7afe07069c46c48a619b9745bcdef5"
          ]
        },
        "id": "f93b8354",
        "outputId": "43abda79-7df0-4699-da06-8f9f6bc974c9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "350837d567f14ea49fdb1e11d0af5941",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/818 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "209dd26a8d5d41dba15d8b4dc3174ea3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6543dd5689e44cc1ac46f504d9e3e570",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8b435189acc46b59d3f5450e7f17c7b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "203f488bee0b4fc2902a6e7feb29616f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8423bc9208da4f3b8edbac1755cba07a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/481M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b7afe07069c46c48a619b9745bcdef5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at google/gemma-2-2b and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Set up model\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float32\n",
        ")\n",
        "\n",
        "# Initialize model with proper padding token configuration\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"google/gemma-2-2b\",\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    num_labels=2,\n",
        "    torch_dtype=torch.float32,\n",
        "    pad_token_id=tokenizer.pad_token_id,  # Set pad_token_id to eos_token_id\n",
        ")\n",
        "\n",
        "# Configure model padding token\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.use_cache = False  # Disable cache to prevent memory issues\n",
        "\n",
        "# Configure LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r=4,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e08650",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-05T15:15:46.544753Z",
          "iopub.status.busy": "2025-01-05T15:15:46.544497Z",
          "iopub.status.idle": "2025-01-05T15:15:46.648879Z",
          "shell.execute_reply": "2025-01-05T15:15:46.648283Z"
        },
        "papermill": {
          "duration": 0.138667,
          "end_time": "2025-01-05T15:15:46.650133",
          "exception": false,
          "start_time": "2025-01-05T15:15:46.511466",
          "status": "completed"
        },
        "tags": [],
        "id": "b9e08650"
      },
      "outputs": [],
      "source": [
        "# Prepare data loaders\n",
        "\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "def get_balanced_sampler(dataset):\n",
        "    labels = [example['labels'] for example in dataset]\n",
        "    class_counts = np.bincount(labels)\n",
        "    weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
        "    sample_weights = weights[labels]\n",
        "\n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=sample_weights,\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True\n",
        "    )\n",
        "    return sampler\n",
        "\n",
        "# Use in DataLoader\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "train_dataloader = DataLoader(\n",
        "    encoded_train,\n",
        "    sampler=get_balanced_sampler(encoded_train),\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator\n",
        ")\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    encoded_test,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13607a68",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-05T15:15:46.715722Z",
          "iopub.status.busy": "2025-01-05T15:15:46.715486Z",
          "iopub.status.idle": "2025-01-05T15:15:46.722496Z",
          "shell.execute_reply": "2025-01-05T15:15:46.721824Z"
        },
        "papermill": {
          "duration": 0.041121,
          "end_time": "2025-01-05T15:15:46.723552",
          "exception": false,
          "start_time": "2025-01-05T15:15:46.682431",
          "status": "completed"
        },
        "tags": [],
        "id": "13607a68"
      },
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-4,\n",
        "    weight_decay=0.01,\n",
        "    eps=1e-8,\n",
        "    betas=(0.9, 0.999)\n",
        ")\n",
        "\n",
        "# Add learning rate scheduler\n",
        "num_epochs = 10\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "\n",
        "# Calculate warmup steps (10% of total steps)\n",
        "# num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "# Create scheduler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b195f93f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-05T15:15:46.788539Z",
          "iopub.status.busy": "2025-01-05T15:15:46.788324Z",
          "iopub.status.idle": "2025-01-05T15:34:52.590661Z",
          "shell.execute_reply": "2025-01-05T15:34:52.589628Z"
        },
        "papermill": {
          "duration": 1145.836318,
          "end_time": "2025-01-05T15:34:52.592173",
          "exception": false,
          "start_time": "2025-01-05T15:15:46.755855",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "13a4b13110144f28946e3c57d760aef8"
          ]
        },
        "id": "b195f93f",
        "outputId": "5cfadbd4-8269-4e42-f1b3-e4e69d0242ff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13a4b13110144f28946e3c57d760aef8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/400 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1:\n",
            "Average Training Loss: 0.5237\n",
            "Evaluation Loss: 0.3458\n",
            "Accuracy: 0.9250\n",
            "\n",
            "Epoch 2:\n",
            "Average Training Loss: 0.1649\n",
            "Evaluation Loss: 0.3480\n",
            "Accuracy: 0.9500\n",
            "\n",
            "Epoch 3:\n",
            "Average Training Loss: 0.0648\n",
            "Evaluation Loss: 0.3428\n",
            "Accuracy: 0.9437\n",
            "\n",
            "Epoch 4:\n",
            "Average Training Loss: 0.0366\n",
            "Evaluation Loss: 0.3444\n",
            "Accuracy: 0.9563\n",
            "\n",
            "Epoch 5:\n",
            "Average Training Loss: 0.0016\n",
            "Evaluation Loss: 0.3683\n",
            "Accuracy: 0.9625\n",
            "\n",
            "Epoch 6:\n",
            "Average Training Loss: 0.0000\n",
            "Evaluation Loss: 0.3798\n",
            "Accuracy: 0.9688\n",
            "\n",
            "Epoch 7:\n",
            "Average Training Loss: 0.0228\n",
            "Evaluation Loss: 0.3647\n",
            "Accuracy: 0.9625\n",
            "\n",
            "Epoch 8:\n",
            "Average Training Loss: 0.0000\n",
            "Evaluation Loss: 0.3640\n",
            "Accuracy: 0.9625\n",
            "\n",
            "Epoch 9:\n",
            "Average Training Loss: 0.0000\n",
            "Evaluation Loss: 0.3746\n",
            "Accuracy: 0.9688\n",
            "\n",
            "Epoch 10:\n",
            "Average Training Loss: 0.0000\n",
            "Evaluation Loss: 0.3752\n",
            "Accuracy: 0.9688\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        if torch.isnan(loss).any():\n",
        "            print(f\"NaN loss detected at batch {batch_idx}!\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            avg_loss = total_loss / (batch_idx + 1)\n",
        "            print(f\"Epoch {epoch+1}, Batch {batch_idx+1}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in eval_dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "\n",
        "            eval_loss += outputs.loss.item()\n",
        "            predictions.extend(torch.argmax(outputs.logits, dim=-1).cpu().numpy())\n",
        "            references.extend(batch[\"labels\"].cpu().numpy())\n",
        "\n",
        "    eval_loss /= len(eval_dataloader)\n",
        "    accuracy = np.mean(np.array(predictions) == np.array(references))\n",
        "\n",
        "    scheduler.step(eval_loss)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}:\")\n",
        "    print(f\"Average Training Loss: {total_loss/len(train_dataloader):.4f}\")\n",
        "    print(f\"Evaluation Loss: {eval_loss:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b926dc15",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-05T15:34:52.659374Z",
          "iopub.status.busy": "2025-01-05T15:34:52.659090Z",
          "iopub.status.idle": "2025-01-05T15:34:53.476103Z",
          "shell.execute_reply": "2025-01-05T15:34:53.475210Z"
        },
        "papermill": {
          "duration": 0.851837,
          "end_time": "2025-01-05T15:34:53.477497",
          "exception": false,
          "start_time": "2025-01-05T15:34:52.625660",
          "status": "completed"
        },
        "tags": [],
        "id": "b926dc15",
        "outputId": "456a9060-d4b2-4548-a590-57e43314922f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('AI_Mala_google_gemma_final_model_updated2/tokenizer_config.json',\n",
              " 'AI_Mala_google_gemma_final_model_updated2/special_tokens_map.json',\n",
              " 'AI_Mala_google_gemma_final_model_updated2/tokenizer.model',\n",
              " 'AI_Mala_google_gemma_final_model_updated2/added_tokens.json',\n",
              " 'AI_Mala_google_gemma_final_model_updated2/tokenizer.json')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the model\n",
        "model.save_pretrained(\"AI_Mala_google_gemma_final_model_updated2\")\n",
        "tokenizer.save_pretrained(\"AI_Mala_google_gemma_final_model_updated2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78e70f78",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-05T15:34:53.544484Z",
          "iopub.status.busy": "2025-01-05T15:34:53.544230Z",
          "iopub.status.idle": "2025-01-05T15:35:03.784925Z",
          "shell.execute_reply": "2025-01-05T15:35:03.784064Z"
        },
        "papermill": {
          "duration": 10.275438,
          "end_time": "2025-01-05T15:35:03.786463",
          "exception": false,
          "start_time": "2025-01-05T15:34:53.511025",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "efb47721ca284273a23e5223128cd44b",
            "3bf7f76354e64dd0bdfde92b593d7fc8",
            "68b91aa4d0804bc1ab7c05efa9116409",
            "665f4d3845864d4e8db1a4e91a398adb",
            "2cc043c3c06849fc93cdc09a1d21ccb2",
            "6c48d861717d43fea8daa20c8c271131"
          ]
        },
        "id": "78e70f78",
        "outputId": "4f038e64-c728-4f2b-e9bd-2ca94d4fe517"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efb47721ca284273a23e5223128cd44b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at google/gemma-2-2b and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bf7f76354e64dd0bdfde92b593d7fc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/3.23M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68b91aa4d0804bc1ab7c05efa9116409",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "665f4d3845864d4e8db1a4e91a398adb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cc043c3c06849fc93cdc09a1d21ccb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c48d861717d43fea8daa20c8c271131",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/ka05ar/AI_Mala_google_gemma_test_updated2/commit/8586acb7793c5a6895b429663fef469165b69633', commit_message='Upload tokenizer', commit_description='', oid='8586acb7793c5a6895b429663fef469165b69633', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ka05ar/AI_Mala_google_gemma_test_updated2', endpoint='https://huggingface.co', repo_type='model', repo_id='ka05ar/AI_Mala_google_gemma_test_updated2'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load the locally saved model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"AI_Mala_google_gemma_final_model_updated2\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"AI_Mala_google_gemma_final_model_updated2\")\n",
        "\n",
        "# Push to Hugging Face Hub\n",
        "model.push_to_hub(\"ka05ar/AI_Mala_google_gemma_test_updated2\")\n",
        "tokenizer.push_to_hub(\"ka05ar/AI_Mala_google_gemma_test_updated2\")"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1463.359718,
      "end_time": "2025-01-05T15:35:06.456235",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-01-05T15:10:43.096517",
      "version": "2.6.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}